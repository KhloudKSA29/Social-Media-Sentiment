# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VRnbLx6JxXQBHS2yuWJKWfgIGiAOLo9Q
"""

import csv

# تحميل البيانات من ملف CSV
with open('sentimentdataset.csv', mode='r') as file:
    reader = csv.DictReader(file)
    data = list(reader)

# عرض أول 5 صفوف للتأكد من تحميل البيانات بشكل صحيح
for row in data[:5]:
    print(row)

columns_to_check = ['Text', 'Sentiment', 'User', 'Platform', 'Hashtags', 'Country', 'Year', 'Month', 'Day', 'Hour']
seen = set()
duplicates = []

# التحقق من الصفوف المكررة بناءً على الأعمدة المحددة
for row in data:
    # إنشاء مفتاح فريد مكون من القيم في الأعمدة المحددة
    row_key = tuple(row[column] for column in columns_to_check)

    if row_key in seen:
        duplicates.append(row)
    else:
        seen.add(row_key)

# عرض عدد الصفوف المكررة
print(f"عدد الصفوف المكررة: {len(duplicates)}")

# عرض أول 5 صفوف مكررة (إذا وجدت)
for row in duplicates[:5]:
    print(row)

# عرض كل الصفوف المكررة
print(f"عدد الصفوف المكررة: {len(duplicates)}")

# عرض جميع الصفوف المكررة
for row in duplicates:
    print(row)

# تحميل البيانات مع تجاهل العمود غير المطلوب
data = pd.read_csv('sentimentdataset.csv', index_col=0)

# عرض أول 5 صفوف للتحقق من البيانات
print(dUnnamedata.head())

# الأعمدة التي سيتم فحص القيم المكررة فيها
columns_to_check = ['Text', 'Sentiment', 'User', 'Platform', 'Hashtags', 'Country', 'Year', 'Month', 'Day', 'Hour']

# التحقق إذا كانت هناك قيم مكررة في الأعمدة المحددة
has_duplicates = data[columns_to_check].duplicated().any()

# عرض النتيجة
if has_duplicates:
    print("هناك قيم مكررة.")
else:
    print("لا توجد قيم مكررة.")

# إزالة الصفوف المكررة
data_cleaned = data.drop_duplicates(subset=columns_to_check)

# عرض البيانات بعد إزالة المكررات
print(data_cleaned.head())

# التحقق إذا كانت هناك قيم مكررة بعد إزالة المكررات
has_duplicates_after_cleaning = data_cleaned[columns_to_check].duplicated().any()

# عرض النتيجة
if has_duplicates_after_cleaning:
    print("لا يزال هناك قيم مكررة.")
else:
    print("لا توجد قيم مكررة.")

missing_values = df.isnull().sum()
print(missing_values)

# التحقق من القيم المفقودة في الأعمدة
missing_values = data.isnull().sum()

# عرض الأعمدة التي تحتوي على قيم مفقودة
print(missing_values)

# التأكد من نوع البيانات في الأعمدة
print(data.dtypes)

from transformers import pipeline

# تحميل نموذج تحليل المشاعر بشكل صريح
sentiment_analysis = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst-2-english")

# تطبيق التحليل على النصوص
df['Sentiment'] = df['Text'].apply(lambda x: sentiment_analysis(x)[0]['label'])

# عرض النتائج
print(df[['Text', 'Sentiment']].head())

# حساب توزيع المشاعر
sentiment_counts = df['Sentiment'].value_counts()

# طباعة النتائج
print("Sentiment Distribution:")
print(sentiment_counts)

# حساب توزيع المشاعر حسب المنصة
sentiment_by_platform = df.groupby('Platform')['Sentiment'].value_counts()

# طباعة النتائج
print("Sentiment by Platform:")
print(sentiment_by_platform)

# حساب توزيع المشاعر حسب البلد
sentiment_by_country = df.groupby('Country')['Sentiment'].value_counts()

# طباعة النتائج
print("Sentiment by Country:")
print(sentiment_by_country)

# تحليل العلاقة بين الإعجابات والمشاعر
sentiment_vs_likes = df.groupby('Sentiment')['Likes'].mean()

# طباعة النتائج
print("Average Likes for Each Sentiment:")
print(sentiment_vs_likes)

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# كلمات من المنشورات الإيجابية
positive_text = ' '.join(df[df['Sentiment'] == 'POSITIVE']['Text'])
wordcloud_pos = WordCloud(width=800, height=200, background_color='white', colormap='Blues').generate(positive_text)

# عرض السحابة للكلمات الإيجابية
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 3))
plt.imshow(wordcloud_pos, interpolation='bilinear')
plt.axis('off')
plt.title('Most Common Words in Positive Posts', fontsize=14, fontweight='bold', color='green')
plt.show()

# كلمات من المنشورات السلبية
negative_text = ' '.join(df[df['Sentiment'] == 'NEGATIVE']['Text'])
wordcloud_neg = WordCloud(width=800, height=200, background_color='white', colormap='Reds').generate(negative_text)

# عرض السحابة للكلمات السلبية
plt.figure(figsize=(10, 3))
plt.imshow(wordcloud_neg, interpolation='bilinear')
plt.axis('off')
plt.title('Most Common Words in Negative Posts', fontsize=14, fontweight='bold', color='red')
plt.show()

# تحويل البيانات إلى تاريخ
df['Date'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-' + df['Day'].astype(str))

# تجميع البيانات حسب الشهر
sentiment_by_month = df.groupby(df['Date'].dt.month)['Sentiment'].value_counts().unstack().fillna(0)

# رسم بياني
plt.figure(figsize=(12, 6))
sentiment_by_month.plot(kind='line', marker='o', linewidth=3, markersize=8, color=['#4CAF50', '#D32F2F'])

# إعدادات الشكل
plt.title('Sentiment Distribution by Month', fontsize=18, fontweight='bold', color='black')
plt.xlabel('Month', fontsize=14, fontweight='bold')
plt.ylabel('Number of Posts', fontsize=14, fontweight='bold')
plt.xticks(rotation=0, fontsize=12)
plt.yticks(fontsize=12)
plt.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# التأكد من تنسيق القيم بشكل صحيح
df['Sentiment'] = df['Sentiment'].str.strip().str.capitalize()

# تجميع البيانات حسب الساعة ونوع المشاعر
sentiment_by_hour = df.groupby(['Hour', 'Sentiment']).size().unstack(fill_value=0)

# التأكد من تضمين جميع أنواع المشاعر حتى لو كانت غير موجودة
for sentiment in ['Positive', 'Negative', 'Neutral']:
    if sentiment not in sentiment_by_hour.columns:
        sentiment_by_hour[sentiment] = 0

# ترتيب الأعمدة بشكل ثابت
sentiment_by_hour = sentiment_by_hour[['Positive', 'Negative', 'Neutral']]

# إعداد الرسم البياني بحجم أصغر
x = np.arange(len(sentiment_by_hour))
width = 0.3

plt.figure(figsize=(8, 4))  # تقليل حجم الرسم
plt.bar(x - width, sentiment_by_hour['Positive'], width, label='Positive', color='#4CAF50')
plt.bar(x, sentiment_by_hour['Negative'], width, label='Negative', color='#D32F2F')
plt.bar(x + width, sentiment_by_hour['Neutral'], width, label='Neutral', color='#FFC107')

# تخصيص المحاور والعناوين
plt.xlabel('Hour', fontsize=12, fontweight='bold')
plt.ylabel('Number of Posts', fontsize=12, fontweight='bold')
plt.title('Sentiment Distribution by Hour', fontsize=14, fontweight='bold', color='black')
plt.xticks(ticks=x, labels=sentiment_by_hour.index, rotation=0, fontsize=10)
plt.legend(fontsize=10)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# حساب متوسط التفاعل (الإعجابات وإعادة التغريد) لكل نوع من المشاعر
sentiment_engagement = df.groupby('Sentiment')[['Likes', 'Retweets']].mean()

# التأكد من ترتيب المشاعر بشكل ثابت
sentiment_engagement = sentiment_engagement.reindex(['Positive', 'Negative', 'Neutral'])

# إعداد الألوان لكل نوع مشاعر
colors = ['#4CAF50', '#D32F2F', '#FFC107']

# إعداد الرسم البياني
x = np.arange(len(sentiment_engagement))
width = 0.3

plt.figure(figsize=(8, 4))  # تصغير حجم الرسم
bars_likes = plt.bar(x - width/2, sentiment_engagement['Likes'], width, label='Likes', color=colors)
bars_retweets = plt.bar(x + width/2, sentiment_engagement['Retweets'], width, label='Retweets', color=colors, alpha=0.7)

# إضافة الأرقام فوق الأعمدة
for bar in bars_likes:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.1, round(yval, 2), ha='center', va='bottom', fontsize=10)

for bar in bars_retweets:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.1, round(yval, 2), ha='center', va='bottom', fontsize=10)

# تخصيص المحاور والعناوين
plt.xlabel('Sentiment', fontsize=12, fontweight='bold')
plt.ylabel('Average Engagement', fontsize=12, fontweight='bold')
plt.title('User Engagement by Sentiment', fontsize=14, fontweight='bold', color='black')
plt.xticks(ticks=x, labels=sentiment_engagement.index, fontsize=10)
plt.legend(fontsize=10)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from collections import Counter
import pandas as pd
import re


# اختر النصوص السلبية والإيجابية
negative_texts = data_cleaned[data_cleaned['Sentiment'] == 'Negative']['Text']
positive_texts = data_cleaned[data_cleaned['Sentiment'] == 'Positive']['Text']

# دالة لتنظيف النصوص
def clean_text(text):
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)  # إزالة المسافات الزائدة
    text = re.sub(r'[^\w\s]', '', text)  # إزالة العلامات الخاصة
    return text

# تنظيف النصوص السلبية والإيجابية
clean_negative_texts = [clean_text(text) for text in negative_texts]
clean_positive_texts = [clean_text(text) for text in positive_texts]

# دمج النصوص السلبية والإيجابية
negative_words = ' '.join(clean_negative_texts).split()
positive_words = ' '.join(clean_positive_texts).split()

# حساب تكرار الكلمات
negative_word_counts = Counter(negative_words)
positive_word_counts = Counter(positive_words)

# الحصول على أكثر 10 كلمات تكرارًا
top_negative_words = negative_word_counts.most_common(10)
top_positive_words = positive_word_counts.most_common(10)

# رسم الكلمات الأكثر شيوعًا في النصوص السلبية (أفقي)
plt.figure(figsize=(6, 4))  # حجم أصغر
plt.barh([word[0] for word in top_negative_words],
         [word[1] for word in top_negative_words],
         color='darkred', edgecolor='black', height=0.7)

# إضافة النسب المئوية
total_negative = sum([word[1] for word in top_negative_words])
for i, word in enumerate(top_negative_words):
    plt.text(word[1] + 0.2, i, f'{(word[1]/total_negative)*100:.1f}%',
             va='center', fontweight='bold', fontsize=10, color='black')

plt.title('Top 10 Most Frequent Words in Negative Sentiment Texts', fontsize=12, fontweight='bold')
plt.xlabel('Frequency', fontsize=10)
plt.ylabel('Words', fontsize=10)
plt.xticks(fontsize=8)
plt.yticks(fontsize=8)
plt.tight_layout()  # لتحسين العرض
plt.show()

# رسم الكلمات الأكثر شيوعًا في النصوص الإيجابية (أفقي)
plt.figure(figsize=(6, 4))  # حجم أصغر
plt.barh([word[0] for word in top_positive_words],
         [word[1] for word in top_positive_words],
         color='darkgreen', edgecolor='black', height=0.7)

# إضافة النسب المئوية
total_positive = sum([word[1] for word in top_positive_words])
for i, word in enumerate(top_positive_words):
    plt.text(word[1] + 0.2, i, f'{(word[1]/total_positive)*100:.1f}%',
             va='center', fontweight='bold', fontsize=10, color='black')

plt.title('Top 10 Most Frequent Words in Positive Sentiment Texts', fontsize=12, fontweight='bold')
plt.xlabel('Frequency', fontsize=10)
plt.ylabel('Words', fontsize=10)
plt.xticks(fontsize=8)
plt.yticks(fontsize=8)
plt.tight_layout()  # لتحسين العرض
plt.show()

import matplotlib.pyplot as plt

# تحديد الكلمات السلبية الأكثر شيوعًا
negative_words = ['Fear', 'Sadness', 'Anger', 'Frustration', 'Loneliness', 'Grief']
counts = [negative_words.count(word) for word in negative_words]

# إنشاء رسم بياني دائري
plt.figure(figsize=(6, 6))  # جعل الرسم البياني أكثر تناسبًا
plt.pie(counts, labels=negative_words, autopct='%1.1f%%', startangle=140, colors=['#FF6666', '#FF6347', '#FF4500', '#FF1493', '#DC143C', '#B22222'])

# إضافة العنوان
plt.title('Sentiment Words Distribution in Negative Texts')

# عرض الرسم البياني
plt.axis('equal')  # لضمان أن الشكل دائري
plt.show()